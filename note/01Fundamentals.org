#+TITLE: Fundamentals

* DONE 00Intro
  CLOSED: [2016-12-31 Sat 14:57]
  - State "DONE"       from "TODO"       [2016-12-31 Sat 14:57]
** Course overview

+ Algorithm
+ Data structure

** Why study algorithms?

+ Their impact is broad and far-reaching.
+ Old roots, new opportunities.
+ To solve problems that could not otherwise be addressed.
+ For intellectual stimulation.
+ To become a proficient programmer.
+ They may unlock the secrets of life and of the universe.
+ For fun and profit.

** Resources

+ [[http://algs4.cs.princeton.edu/home/][Booksite]]
+ Textbook: Algorithm(4e)

* DONE 15Union-Find
  CLOSED: [2017-01-01 Sun 15:12]
  - State "DONE"       from "TODO"       [2017-01-01 Sun 15:12]
** [Subtext of today’s lecture (and this course)]

+ Steps to developing a usable algorithm.
+ The scientific method.
+ Mathematical analysis.

** Dynamic connectivity

+ Given a set of N objects.
  - Union command.
  - Find/connected query

+ Example: PICTURE

+ Modeling the objects.
  - Applications involve manipulating objects of all types.
  - When programming, convenient to name objects 0 to N-1.

+ Modeling the connections.
  - We assume "is connected to" is an equivalence relation.
  - Connected components: Maximal set of objects that are mutually connected.

+ Union-find data type (API)
  - Goal: Design efficient data structure for union-find.

#+TABLE_NAME: UF
|---------------------------------+------------------------------------------------------------------|
| UF(int N)                       | initialize union-find data structure with N objects (0 to N – 1) |
| void union(int p, int q)        | add connection between p and q                                   |
| boolean connected(int p, int q) | are p and q in the same component?                               |
|---------------------------------+------------------------------------------------------------------|
| int find(int p)                 | component identifier for p (0 to N – 1)                          |
| int count()                     | number of components                                             |
|---------------------------------+------------------------------------------------------------------|

+ Dynamic-connectivity client

** Quick-find [eager approach]

+ Data structure.
  - Integer array id[] of length N.
  - Interpretation: p and q are connected iff they have the same id. 

+ Find: Check if p and q have the same id.

+ Union: To merge components containing p and q, change all entries whose id
  equals id[p] to id[q].

+ Demo: ANIMATION

+ Java implementation: CODE

+ Quick-find is to slow.
  - Cost model: Number of array accesses.
  - Defect: Union too expensive.

|------------+------------+-------+------+
| algorithm  | initialize | union | find |
|------------+------------+-------+------+
| quick-find | N          | N     | 1    |
|------------+------------+-------+------+

+ Quadratic algorithms do not scale
  - Rough standard(for now).
  - Ex. Huge problem for quick-find.
  - Quadratic algorithms don't scale with technology.

** Union-find [lazy approach]

+ Data structure.
  - Integer array id[] of length N.
  - Interpretation: id[i] is parent of i.
  - Root of i is id[id[id[...id[i]...]]].

+ Find: Check if p and q have the same root.

+ Union: To merge components containing p and q, set the id of p's root to the
  id of q's root.

+ Demo: ANIMATION

+ Java implementation: CODE

+ Quick-union is also too slow.
  - Cost model: Number of array accesses.
  - Quick-find defect: Trees are flat, but too expensive to keep them flat.
  - Quick-union defect: Trees can get tall.

| algorithm   | initialize | union | find | Comment    |
|-------------+------------+-------+------+------------|
| quick-find  | N          | N     | 1    |            |
| quick-union | N          | N†    | N    | worst case |

** Improvements
*** Improvement 1: weighting

+ Weighted quick-union
  - Modify quick-union to avoid tall trees.
  - Keep track of size of each tree(number of objects).
  - Balance by linking root of smaller tree to root of larger tree(reasonable
    alternative union by height or "rank")

+ Demo: ANIMATION

+ Quick-union and weighted quick-union example: PICTURE

+ Java implementation: CODE
  - Data structure: Same as quick-union, but maintain extra array sz[i] to
    count number of objects in the tree rooted at i.
  - Find: Identical to quick-union.
  - Union: Modify quick-union to:
    + Link root of smaller tree to root of larger tree.
    + Update the sz[] array.

+ Running time.
  - Find: takes time proportional to depth of p and q.
  - Union: takes constant time, given roots.

+ Proposition: Depth of any node x is at most lgN.

+ Pf. When does depth of x increase?

| algorithm   | initialize | union | connected |
|-------------+------------+-------+-----------|
| quick-find  | N          | N     | 1         |
| quick-union | N          | N†    | N         |
| weighted QU | N          | lgN†  | lgN       |

*** Improvement 2: path compression

+ Quick union with path compression: Just after computing the root of p, set
  the id of each examined node to the node of that root.

+ Java implementation: CODE
  - Two-pass implementation: Add second loop to root() to set id[] of each
    examined node to the root.
  - Simpler one-pass variant: Make every other node in path point to its
    grandparent(thereby halving path length).
  - In practice. Keeps tree almost completely flat.

+ Weighted quick-union with path compression: amortized analysis
  - Proposition: [Hopcroft-Ulman, Tarjan] Starting from an empty data
    structure, any sequence of M union-find ops on N objects makes ≤ c ( N + M
    lg* N ) array accesses.
  - Linear-time algorithm for M union-find ops on N objects?
    + In theory, WQUPC is not quite linear.
    + In practice, WQUPC is linear.
  - Amazing fact: [Fredman-Saks] No linear-time algorithm exists.

*** Summary

+ M union-find operations on a set of N objects

| algorithm                      | worst-case time |
|--------------------------------+-----------------|
| quick-find                     | MN              |
| quick-union                    | MN              |
| weighted QU                    | N + M lgN       |
| QU + path compression          | N + M lgN       |
| weighted QU + path compression | N + M lg*N      |

** Applications

+ Union-find applications
  - Percolation. 
  - Games (Go, Hex).
  - Dynamic connectivity. ✓
  - Least common ancestor.
  - Equivalence of finite state automata.
  - Hoshen-Kopelman algorithm in physics.
  - Hinley-Milner polymorphic type inference.
  - Kruskal's minimum spanning tree algorithm.
  - Compiling equivalence statements in Fortran.
  - Morphological attribute openings and closings.
  - Matlab's bwlabel() function in image processing.

+ Percolation: A model for many physical systems.
  - N-by-N grid of sites
  - Each site is open with probability p (or blocked with probability 1 - p).
  - System percolates iff top and bottom are connected by open sites.

| model                 | system      | vacant site | occupied site | percolates   |
|-----------------------+-------------+-------------+---------------+--------------|
| electricity           | electricity | conductor   | insulated     | conducts     |
| fluid flow            | material    | empty       | blocked       | porous       |
| social interpretation | population  | person      | empty         | communicates |

+ Likelihood of percolation.
  - Depend on site vacancy probability.

+ Percolation phase transition
  - When N is large, theory guarantees a sharp threshold p*.
    + p > p*: almost certainly percolates.
    + p < p*: almost certainly does not percolate.
  - Q: What is the value of p* ?

+ Monte Carlo simulation
  - Initialize N-by-N whole grid to be blocked.
  - Declare random sites open until top connected to bottom.
  - Vacancy percentage estimates p*.

+ Dynamic connectivity solution to estimate percolation threshold
  - How to check whether an N-by-N system percolates?
    + Create an object for each site and name them 0 to N^2 – 1.
    + Sites are in same component if connected by open sites.
    + Percolates iff any site on bottom row is connected to site on top row.
  - Clever trick: Introduce 2 virtual sites (and connections to top and
    bottom).
    + Percolates iff virtual top site is connected to virtual bottom site.
  - How to model opening a new site?
    + Mark new site as open; connect it to all of its adjacent open sites.
  - What is percolation threshold p*?
    + About 0.592746 for large square lattices.

* DONE 14Analysis-Of-Algorithms
  CLOSED: [2017-01-03 Tue 16:01]
  - State "DONE"       from "TODO"       [2017-01-03 Tue 16:01]
** Introduction

+ Cast of characters.
  - Programmer
  - Client
  - Theoretician
  - Blocking and tacking
  - Student

+ Running time
  - Babbage's Analytic Engine

+ Reasons to analyze algorithms.
  - Avoid performance bugs.
  - Predict performance.
  - Compare algorithms.
  - Provide guarantees.
  - Understand theoretical basis.

+ Some algorithmic successes.
  - Discrete Fourier transform.
  - N-body simulation.

+ The challenge: Will my program be able to solve a large practical input?
  - Why is my program so slow?
  - Why does it run out of memory?
  - Insight. [Knuth 1970s] Use scientific method to understand performance.

+ Scientific method applied to analysis of algorithmic.
  - Scientific method.
    + Observe
    + Hypothesize
    + Predict
    + Verify
    + Validate
  - Principles
    + Experiment must be reproducible.
    + Hypotheses must be falsifiable.
  - Feature of the natural world.
** Observation

+ Example: 3-SUM
  - 3-SUM: Given N distinct integers, how many triples sum to exactly zero?
  - Context: Deeply related to problems in computational geometry.

+ S-SUM: brute-force algorithm: CODE

+ Measuring the running time
  - Manual: Clock
  - Automatic: Stopwatch

+ Empirical analysis.
  - Run the program for various input sizes and measure running time.
    
+ Data analysis.
  - Standard plot: Plot running time T (N) vs. input size N.
  - Log-log plot: Plot running time T (N) vs. input size N using log-log scale.
  - Regression.
  - Hypothesis.

+ Prediction and validation.
  - Hypothesis.
  - Predictions.
  - Observation.

+ Doubling hypothesis: Quick way to estimate b in a power-law relationship.
  - Run program, doubling the size of the input.
  - Hypothesis: Running time is about a N^b with b = lg ratio.
  - Caveat: Cannot identify logarithmic factors with doubling hypothesis.
  - Run the program (for a sufficient large value of N) and solve for a.

+ Experimental algorithmics.
  - System independent effects. determines exponent b in power law.
    + Algorithm.
    + Input data.
  - System dependent effects. determines constant a in power law
    + Hardware.
    + Software.
    + System.
  - Bad news: Difficult to get precise measurements.
  - Good news: Much easier and cheaper than other sciences.

** Mathematical models

+ Mathematical models for running time.
  - Total running time: sum of cost * frequency for all operations.
    + Need to analyze program to determine set of operations.
    + Cost depends on machine, compiler.
    + Frequency depends on algorithm, input data.
  - In principle, accurate mathematical models are available.

+ Cost of basic operations: TABLE
  - Novice mistake: Abusive string concatenation.

+ How many instructions as a function of input size N ?
  - Example: 1-SUM
  - Example: 2-SUM

+ Simplifying the calculations.
  - Maybe we should just count the ones that are most expensive.
    
+ Simplification 1: cost model
  - Use some basic operation as a proxy for running time.

+ Simplification 2: tilde notation
  - Estimate running time (or memory) as a function of input size N.
  - Ignore lower order terms.
    + when N is large, terms are negligible 
    + when N is small, we don't care
  - Technical definition: The limit of f(N) divide g(N) equals 1.

+ Approximately how many array accesses as a function of input size N ?
  - Example: 2-SUM: ~ N^2
  - Example: 3-SUM: ~ 1/2 N^3
  - Bottom line: Use cost model and tilde notation to simplify counts.

+ Estimating a discrete sum
  - Ex1. 1 + 2 + ... + N. ~ 1/2 N^2
  - Ex2. 1^k + 2^k + ... + N^k. ~ 1/(k+1) N^(k+1)
  - Ex3. 1 + 1/2 + 1/3 + ... 1/N. ~ lnN
  - Ex4. 3-sum triple loop. ~ 1/6 N^3

+ Mathematical models for running time.
  - In principle: accurate mathematical models are available.
  - In practice:
    + Formulas can be complicated.
    + Advanced mathematics might be required.
    + Exact models best left for experts.

** Order-of-growth classifications

+ Common order-of-growth classifications
  - Good news: 1, logN, N, NlogN, N^2, N^3,and 2^N suffices to describe.
  - Bottom line: Need linear or linearithmic alg to keep pace with Moore's law.

+ Binary search.
  - Goal: Given a sorted array and a key, find index of the key in the array?
  - Binary search. Compare key against middle entry.
    + Too small, go left.
    + Too big, go right.
    + Equal, found.

+ Binary search: Java implementation. CODE
  - Trivial to implement? NO!NO!
  - Invariant: If key appears in the array a[], then a[lo] ≤ key ≤ a[hi].

+ Binary search: mathematical analysis.
  - Proposition: Binary search uses at most 1 + lg N key compares to search in
    a sorted array of size N.
  - Def: T (N) ≡ # key compares to binary search a sorted subarray of size ≤ N.
  - Binary search recurrence. T(N) ≤ T(N / 2) + 1 for N > 1, with T(1) = 1.
  - Pf sketch: T(N) ≤ T(N/2) + 1 ≤ T(N/4) + 1 + 1 ≤ ... ≤ T(N/N) + 1 + ... 1 ≤
    1 + lgN

+ An N^2 logN algorithm for 3-SUM
  - Sorting-based algorithm.
    + Step 1: Sort the N numbers.
    + Step 2: For each pair of numbers a[i] and a[j], binary search for
      -(a[i] + a[j]).
  - Analysis: Order of growth is N 2 log N.
    + Step1: N^2 with insertion sort
    + Step2: N^ logN with binary search.

+ Comparing programs.
  - Hypothesis: The sorting-based N 2 log N algorithm for 3-SUM is
    significantly faster in practice than the brute-force N 3 algorithm. 
  - Guiding principle: Typically, better order of growth ⇒ faster in practice.

** Theory of algorithms

+ Types of analyses.
  - Best case: Lower bound on cost.
  - Worst case: Upper bound on cost.
  - Average case: “Expected” cost for random input.
  - Actual data might not match input model?
    + Need to understand input to effectively process it.
    + Approach 1: design for the worst case.
    + Approach 2: randomize, depend on probabilistic guarantee.

+ Theory of algorithms.
  - Goals.
    + Establish “difficulty” of a problem.
    + Develop “optimal” algorithms.
  - Approach.
    + Suppress details in analysis: analyze “to within a constant factor”.
    + Eliminate variability in input model by focusing on the worst case.
  - Optimal algorithm.
    + Performance guarantee (to within a constant factor) for any input.
    + No algorithm can provide a better performance guarantee.

+ Commonly-used notations in the theory of algorithms.
  - Big Theta(Θ): asymptotic order of growth.
  - Big Oh(O): O(X) and smaller.
  - Big Omega(Ω): Ω(X) and larger.

+ Theory of algorithms: example 1.
  - Goals.
    + Establish “difficulty” of a problem and develop “optimal” algorithms.
    + Ex. 1-SUM = “Is there a 0 in the array? ”
  - Upper bound. A specific algorithm.
    + Ex. Brute-force algorithm for 1-SUM: look at every array entry.
    + Running time of the optimal algorithm for 1-SUM is O(N).
  - Lower bound. Proof that no algorithm can do better.
    + Ex. Have to examine all N entries (any unexamined one might 0).
    + Running time of the optimal algorithm for 1-SUM is Ω(N).
  - Optimal algorithm.
    + Lower bound equals upper bound (to within a constant factor).
    + Ex. Brute-force algorithm for 1-SUM is optimal: its running is Θ(N).

+ Theory of algorithms: example 2.
  - Goals.
    + Establish “difficulty” of a problem and develop “optimal” algorithms.
    + ex. 3-SUM.
  - Upper bound. A specific algorithm.
    + Ex. Improved algorithm for 3-SUM.
    + Running time of the optimal algorithm for 3-SUM is O(N^2 logN).
  - Lower bound. Proof that no algorithm do better.
    + Ex. Have to examine all N entries to solve 3-SUM.
    + Running time of the optimal algorithm for solving 3-SUM is Ω(N).
  - Open problems.

+ Algorithm design approach.
  - Start.
    + Develop an algorithm.
    + Prove a lower bound.
  - Gap?
    + Lower the upper bound (discover a new algorithm).
    + Raise the lower bound (more difficult).
  - Golden Age of Algorithm Design.
    + 1970s-.
    + Steadily decreasing upper bounds for many important problems.
    + Many known optimal algorithms.
  - Caveats.
    + Overly pessimistic to focus on worst case?
    + Need better than “to within a constant factor” to predict performance.

+ Commonly-used notations
  - Common mistake: Interpreting big-Oh as an approximate model.
  - This course: Focus on approximate models: use Tilde-notation(~).

** Memory

+ Basics
  - Bit: 0 or 1.
  - Byte: 8 bits.
  - Megabyte (MB): 1 million or 2^20 bytes.
  - Gigabyte (Gb): 1 billion or 2^30 bytes.
  - 64-bit machine. We assume a 64-bit machine with 8 byte pointers.
    + Can address more memory.
    + Points use more space.

+ Typical memory usage summary.
  - Total memory usage for a data type value:
    + Primitive type: 4 bytes for int, 8 bytes for double, ... 
    + Object reference: 8 bytes.
    + Array: 24 bytes + memory for each array entry.
    + Object: 16 bytes + memory for each instance variable ・+ 8 bytes if inner
      class (for pointer to enclosing class).
    + Padding: round up to multiple of 8 bytes.
  - Shallow memory usage: Don't count referenced objects.
  - Deep memory usage: If array entry or instance variable is a reference, add
    memory (recursively) for referenced object.
  - Example: WeightedQuickUnionUF

** [Turning the crank: summary]

+ Empirical analysis.
  - Execute program to perform experiments.
  - Assume power law and formulate a hypothesis for running time.
  - Model enables us to make predictions.
+ Mathematical analysis.
  - Analyze algorithm to count frequency of operations.
  - Use tilde notation to simplify analysis.
  - Model enables us to explain behavior.
+ Scientific method.
  - Mathematical model is independent of a particular system; applies to
    machines not yet built.
  - Empirical analysis is necessary to validate mathematical models and to make
    predictions.

* DONE 13Stacks-And-Queues
  CLOSED: [2017-01-08 Sun 23:19]
  - State "DONE"       from "TODO"       [2017-01-08 Sun 23:19]
** [Stacks and queues]

+ Fundamental data types.
  - Value: collection of objects.
  - Operations: insert, remove, iterate, test if empty.
  - Intent is clear when we insert.
  - Which item do we remove?

+ Stack. Examine the item most recently added. LIFO.
+ Queue. Examine the item least recently added. FIFO.

** [Client, implementation, interface]

+ Separate interface and implementation.
  - Ex: stack, queue, bag, priority queue, symbol table, union-find,...

+ Benefits.
  - Client can't know details of implementation =>
    client has many implementation from which to choose.
  - Implementation can't know details of client needs =>
    many clients can re-use the same implementation.
  - Design: creates modular, reusable libraries.
  - Performance: use optimized implementation which it matters.

+ Client: program using operations defined in interface. 
+ Implementation: actual code implementing operations. 
+ Interface: description of data type, basic operations.
 
** Stacks

+ Stack API.
  - Warmup API: Stack of strings data type.
|------------------------+--------------------------------------------------|
| StackOfStrings()       | create an empty stack                            |
| void push(String item) | insert a new string onto stack                   |
| String pop()           | remove and return the string most recently added |
| boolean isEmpty()      | is the stack empty?                              |
|------------------------+--------------------------------------------------|
| int size()             | number of strings on the stack                   |
|------------------------+--------------------------------------------------|

+ Stack test client.
  - Warmup client: Reverse sequence of strings from standard input. CODE.

+ Stack: linked-list representation.
  - Maintain pointer to first node in a linked list; insert/remove from front.
  - Stack pop: linked-list implementation
  - Stack push: linked-list implementation
  - Stack: linked-list implementation in Java: CODE

+ Stack: linked-list implementation performance.
  - Proposition: Every operation takes constant time in the worst case.
  - Proposition: A stack with N items uses ~ 40 N bytes.
  - Remark. This accounts for the memory for the stack (but not the memory for
    strings themselves, which the client owns).

+ Stack: array implementation.
  - Array implementation of a stack.
    + Use array s[] to store N items on stack.
    + push(): add new item at s[N].
    + pop(): remove item from s[N-1].
  - Defect. Stack overflows when N exceeds capacity. [stay tuned]
  - Stack: array implementation: CODE

+ Stack considerations.
  - Overflow and underflow.
    + Underflow: throw exception if pop from an empty stack. 
    + Overflow: use resizing array for array implementation. [stay tuned]
  - Null items: We allow null items to be inserted.
  - Loitering: Holding a reference to an object when it is no longer needed.

** Resizing arrays

+ Stack: resizing-array implementation.
  - Problem: Requiring client to provide capacity does not implement API! 
  - Q: How to grow and shrink array?

+ Q: How to grow array?
  - First try.
    + push(): increase size of array s[] by 1. 
    + pop(): decrease size of array s[] by 1.
  - Too expensive.
    + Need to copy all items to a new array.
    + Inserting first N items takes time proportional to 1 + 2 + ... + N ~ N^2
      / 2.
  - A: If array is full, create a new array of twice the size, and copy items. 
  - Java implementation: CODE
  - Cost of inserting first N items: N + (2 + 4 + 8 + ... + N) ~ 3N.

+ Q: How to shrink array?
  - First try.
    + push(): double size of array s[] when array is full.
    + pop(): halve size of array s[] when array is one-half full.
  - Too expensive in worst case.
    + Consider push-pop-push-pop-... sequence when array is full.
    + Each operation takes time proportional to N.
  - Efficient solution.
    + push(): double size of array s[] when array is full.
    + pop(): halve size of array s[] when array is one-quarter full.
  - Java implementation: CODE    
  - Invariant. Array is between 25% and 100% full.

+ Stack: resizing-array implementation trace: PICTURE

+ Stack resizing-array implementation: performance.
  - Amortized analysis: Average running time per operation over a worst-case
    sequence of operations. 
  - Proposition: Starting from an empty stack, any sequence of M push and pop
    operations takes time proportional to M. 

|-----------+------+-------+-----------|
|           | best | worst | amortized |
|-----------+------+-------+-----------|
| construct | 1    | 1     | 1         |
| push      | 1    | N     | 1         |
| pop       | 1    | N     | 1         |
| size      | 1    | 1     | 1         |
|-----------+------+-------+-----------|

+ Stack resizing-array implementation: memory usage.
  - Proposition. Uses between ~ 8 N and ~ 32 N bytes to represent a stack with
    N items.
    + ~ 8 N when full.
    + ~ 32 N when one-quarter full.

+ Stack implementations: resizing array vs. linked list.
  - Tradeoffs: Can implement a stack with either resizing array or linked list;
    save a link to the list client can use interchangeably. Which one is
    better?
  - Linked-list implementation.
    + Every operation takes constant time in the worst case.
    + Uses extra time and space to deal with the links.
  - Resizing-array implementation.
    + Every operation takes constant amortized time.
    + Less wasted space.

** Queues

+ Queue API.

|---------------------------+---------------------------------------------------|
| QueueOfString()           | create an empty queue                             |
| void enqueue(String item) | insert a new string onto queue                    |
| String dequeue()          | remove and return the string least recently added |
| boolean isEmpty()         | is the queue empty?                               |
|---------------------------+---------------------------------------------------|
| int size()                | number of strings on the queue                    |
|---------------------------+---------------------------------------------------|

+ Queue: linked-list representation
  - Maintain pointer to first and last nodes in a linked list; insert/remove
    from opposite ends.
  - Remark. Identical code to linked-list stack pop().
  - Remark. Special cases for empty queue
  - Java implementation: CODE

+ Queue: resizing array implementation
  - Use array q[] to store items in queue.
  - enqueue(): add new item at q[tail].
  - dequeue(): remove item from q[head].
  - Update head and tail modulo the capacity.
  - Add resizing array.

** Generics

+ Parameterized stack.
  - We implemented: StackOfStrings. 
  - We also want: StackOfURLs, StackOfInts, StackOfVans, ....

+ Bad Attempt 1. Implement a separate stack class for each type.
+ Bad Attempt 2. Implement a stack with items of type Object.
+ Good Attempt 3. Java generics.
  - Guiding principles. Welcome compile-time errors; avoid run-time errors.

+ Generic stack: linked-list implementation. CODE
+ Generic stack: array implementation. CODE
  - Generic array creation not allowed in Java, Use the ugly cast.
  - Unchecked cast.

+ Generic data types: autoboxing
  - Wrapper type.
    + Each primitive type has a wrapper object type.
    + Ex: Integer is wrapper type for int.
  - Autoboxing: Automatic cast between a primitive type and its wrapper.
  - Bottom line: Client code can use generic stack for any type of data.

** Iterators

+ Iteration.
  - Design challenge: Support iteration over stack items by client, without
    revealing the internal representation of the stack. 
  - Java solution: Make stack implement the java.lang.Iterable interface.

+ Iterators.
  - Q. What is an Iterable ?
  - A. Has a method that returns an Iterator.
  - Q. What is an Iterator ?
  - A. Has methods hasNext() and next().
  - Q. Why make data structures Iterable ? 
  - A. Java supports elegant client code.

+ Stack iterator: linked-list implementation. CODE
+ Stack iterator: array implementation. CODE

+ Bag API.
  - Main application: Adding items to a collection and iterating (when order
    doesn't matter).
  - Implementation: Stack (without pop) or queue (without dequeue).

|---------------------------+-------------------------------|
| Bag()                     | create an empty bag           |
| void add(Item x)          | insert a new item onto bag    |
| int size()                | number of items in bag        |
| Iterable<Item> iterator() | iterator for all items in bag |
|---------------------------+-------------------------------|
** Applications

+ Java collections library
  - List interface: java.util.List is API for an sequence of items.
  - Implementations.
    + java.util.ArrayList uses resizing array;
    + java.util.LinkedList uses linked list.
  - java.util.Stack.
    + Supports push(), pop(), and and iteration.
    + Extends java.util.Vector, which implements java.util.List
    + interface from previous slide, including, get() and remove(). Bloated and
      poorly-designed API.
  - Best practices: Use our implementations of Stack, Queue, and Bag.

+ War story (from Assignment 1)
  - Lesson: Don't use a library until you understand its API!
  - This course: Can't use a library until we've implemented it in class.

+ Stack applications
  - Parsing in a compiler.
  - Java virtual machine.
  - Undo in a word processor.
  - Back button in a Web browser.
  - PostScript language for printers. 
  - Implementing function calls in a compiler.
  - ...

+ Function calls.
  - How a compiler implements a function.
    + Function call: push local environment and return address.
    + Return: pop return address and local environment.
  - Recursive function: Function that calls itself.
  - Note: Can always use an explicit stack to remove recursion.

+ Arithmetic expression evaluation.
  - Goal: Evaluate infix expression.
  - Two-stack algorithm. [E. W. Dijkstra]
    + Value: push onto the value stack.
    + Operator: push onto the operator stack.
    + Left parenthesis: ignore.
    + Right parenthesis: pop operator and two values; push the result of
      applying the operator to those values onto the operand stack.
  - Context: An interpreter!
      
+ Dijkstra's two-stack algorithm demo: ANIMATION

+ Arithmetic expression evaluation: CODE

+ Correctness.
  - When algorithm encounters an operator surrounded by two values within
    parentheses, it leaves the result on the value stack.
  - Extensions: More ops, precedence order, associativity.

